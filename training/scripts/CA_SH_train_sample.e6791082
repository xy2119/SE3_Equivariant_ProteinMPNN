/rds/general/user/xy2119/home/ProteinMPNN/training/model_utils.py:1428: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  expand_coef[:,l] += torch.tensor(coef.real**2+coef.imag**2)
/rds/general/user/xy2119/home/ProteinMPNN/training/model_utils.py:1429: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  expand_matrix[:,l**2+l+m] = torch.tensor(coef)
/rds/general/user/xy2119/home/ProteinMPNN/training/model_utils.py:1505: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642969563/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1646.)
  SH_features[where_nan] = 0
Traceback (most recent call last):
  File "/rds/general/user/xy2119/home/ProteinMPNN/training/training.py", line 348, in <module>
    main(args)   
  File "/rds/general/user/xy2119/home/ProteinMPNN/training/training.py", line 221, in main
    log_probs = model(X, S, mask, chain_M, residue_idx, chain_encoding_all, randn_1)
  File "/rds/general/user/xy2119/home/anaconda3/envs/mlfold/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/rds/general/user/xy2119/home/ProteinMPNN/training/model_utils.py", line 1586, in forward
    h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)
  File "/rds/general/user/xy2119/home/ProteinMPNN/training/model_utils.py", line 599, in cat_neighbors_nodes
    h_nn = torch.cat([h_neighbors, h_nodes], -1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 614.00 MiB (GPU 0; 23.65 GiB total capacity; 22.01 GiB already allocated; 531.56 MiB free; 22.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
